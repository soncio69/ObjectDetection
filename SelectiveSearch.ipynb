{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ee7d87",
   "metadata": {},
   "source": [
    "In questo paper viene introdotto l'algoritmo di selective search (Uijlings et al. in 2012).<br>\n",
    "Per mezzo di questa tecnica è possibile identificare automaticamente, all'interno di una immagine, le diverse posizioni dove possono trovarsi oggetti.<br>\n",
    "E' molto più efficiente rispetto all'utilizzo di Image Pyramid e sliding windows.<br>\n",
    "E' un algoritmo di \"Automathic region proposal\" ed è il predecessore degli algoritmi di RPN (Region Proposal Network) che sono ancora più accurati ed efficienti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f26320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5153aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = \"data/gatto_difficile.jpg\"\n",
    "METHOD = \"fast\"\n",
    "#METHOD = \"quality\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16fabbb",
   "metadata": {},
   "source": [
    "L'algoritmo di selective search effettua una over-segmentation dell'immagine utilizzando un algoritmo di \"superpixel\". <br>\n",
    "I pixel che compongono l'immagine vengono aggregati sulla base di 5 misure di similarità:\n",
    "- color similarity\n",
    "- texture similarity\n",
    "- size similarity (privilegiando in prima battuta le regioni di minori dimensioni)\n",
    "- shape similarity (sulla base della compatibilità delle regioni proposte)\n",
    "- un meta similarity measure che è dato dalla combinazione lineare delle precedenti misure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32858a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using *fast* selective search\n"
     ]
    }
   ],
   "source": [
    "# load the input image\n",
    "image = cv2.imread(IMAGE)\n",
    "# initialize OpenCV's selective search implementation and set the\n",
    "# input image\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "ss.setBaseImage(image)\n",
    "# check to see if we are using the *fast* but *less accurate* version\n",
    "# of selective search\n",
    "if METHOD == \"fast\":\n",
    "\tprint(\"[INFO] using *fast* selective search\")\n",
    "\tss.switchToSelectiveSearchFast()\n",
    "# otherwise we are using the *slower* but *more accurate* version\n",
    "else:\n",
    "\tprint(\"[INFO] using *quality* selective search\")\n",
    "\tss.switchToSelectiveSearchQuality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82bf420c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] selective search took 32.8505 seconds\n",
      "[INFO] 11617 total region proposals\n"
     ]
    }
   ],
   "source": [
    "# run selective search on the input image\n",
    "start = time.time()\n",
    "rects = ss.process()\n",
    "end = time.time()\n",
    "# show how along selective search took to run along with the total\n",
    "# number of returned region proposals\n",
    "print(\"[INFO] selective search took {:.4f} seconds\".format(end - start))\n",
    "print(\"[INFO] {} total region proposals\".format(len(rects)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d46e1",
   "metadata": {},
   "source": [
    "Una volta ottenute le regioni che presumibilmente contengono un oggetto, è possibile visualizzarle prima di passare alla successiva fase di classificazione.<br>\n",
    "La visualizzazione avviene a gruppi di 100 regiorni individuate sul totale precedentemente estratto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed1b3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the region proposals in chunks (so we can better\n",
    "# visualize them)\n",
    "for i in range(0, len(rects), 100):\n",
    "    # clone the original image so we can draw on it\n",
    "    output = image.copy()\n",
    "    # loop over the current subset of region proposals\n",
    "    for (x, y, w, h) in rects[i:i + 100]:\n",
    "        # draw the region proposal bounding box on the image\n",
    "        color = [random.randint(0, 255) for j in range(0, 3)]\n",
    "        cv2.rectangle(output, (x, y), (x + w, y + h), color, 2)\n",
    "    # show the output image\n",
    "    cv2.imshow(\"Output\", output)\n",
    "    key = cv2.waitKey(0) & 0xFF\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9e17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-env]",
   "language": "python",
   "name": "conda-env-tf-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
